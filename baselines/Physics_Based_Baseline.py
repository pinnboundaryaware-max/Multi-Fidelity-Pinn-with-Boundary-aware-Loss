# -*- coding: utf-8 -*-
"""PINN+1DSIA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W7qgkZEZGv8ApgpHI_lYcby29m9xfmur
"""

# Imports
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Load data
full_data = pd.read_csv('data_full.csv')

# Separate variables
x_all = full_data.iloc[:, 1:-1].values
y_all = full_data.iloc[:, -1].values.reshape(-1, 1)

# Train-test split
n = len(x_all)
indices = np.random.permutation(n)
split_index = int(n * 0.8)
x_train, x_test = x_all[indices[:split_index]], x_all[indices[split_index:]]
y_train, y_test = y_all[indices[:split_index]], y_all[indices[split_index:]]

# Scaling
scaler_x = StandardScaler()
scaler_y = StandardScaler()
X_train = scaler_x.fit_transform(x_train)
X_test = scaler_x.transform(x_test)
y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

# Tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32, requires_grad=True).to(device)
y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32, requires_grad=True).to(device)
y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32).to(device)

# Constants (SIA PDE)
A, rho, g = 2.4e-24, 917, 9.81
D = (2 * A * (rho * g)**3) / 5

# PINN Model
class PINN_Model(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(PINN_Model, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = torch.tanh(self.fc1(x))
        x = torch.tanh(self.fc2(x))
        return self.fc3(x)

model = PINN_Model(X_train.shape[1], 64, 1).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)

# PDE residual loss (SIA PDE)
def pde_loss(model, X, surf_elv, surf_SMB):
    z_b_pred = model(X)
    H = surf_elv - z_b_pred

    dS_dx = torch.autograd.grad(surf_elv, X, torch.ones_like(surf_elv), create_graph=True)[0][:, 0:1]
    DH5_dSdx = D * (H**5) * dS_dx

    dDH5_dSdx_dx = torch.autograd.grad(DH5_dSdx, X, torch.ones_like(DH5_dSdx), create_graph=True)[0][:, 0:1]

    residual = dDH5_dSdx_dx + surf_SMB

    return torch.mean(residual**2)

# Training
lambda_pde = 0.1
epochs = 30000
for epoch in range(epochs + 1):
    model.train()
    optimizer.zero_grad()

    z_b_pred = model(X_train_tensor)
    data_loss = nn.MSELoss()(z_b_pred, y_train_tensor)

    surf_elv_train = X_train_tensor[:, [2]]
    surf_SMB_train = X_train_tensor[:, [4]]
    physics_loss = pde_loss(model, X_train_tensor, surf_elv_train, surf_SMB_train)

    loss = data_loss + lambda_pde * physics_loss
    loss.backward()
    optimizer.step()

    if epoch % 1000 == 0:
        print(f"Epoch {epoch}, Data Loss: {data_loss.item():.4f}, PDE Loss: {physics_loss.item():.4f}")

# Evaluation
model.eval()
with torch.no_grad():
    y_pred_scaled = model(X_test_tensor)
    y_pred = scaler_y.inverse_transform(y_pred_scaled.cpu().numpy())
    y_true = scaler_y.inverse_transform(y_test_tensor.cpu().numpy())

# Metrics
mae = mean_absolute_error(y_true, y_pred)
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
r2 = r2_score(y_true, y_pred)

print(f"\nFinal Evaluation:\nMAE: {mae:.4f}\nRMSE: {rmse:.4f}\nRÂ²: {r2:.4f}")